The Topology of Time with Matt Pirkowski
https://www.youtube.com/watch?v=IOarnRgUjyM

Transcript:
(00:00) hello I have Matt praski here you may have heard me praising him in just about every podcast that I do with people um he's a very intelligent and uh semantically dense speaker uh you can take his posts from Twitter and get essays and essays and essays out of them by just passing them to GPT uh he has a whole set of language that creates for a very efficient neural map in relation to very complex phenomena that are very difficult to understand and we both are in my perception very aligned on a lot of things we use different language he
(00:46) uses much more precise language and we may buttheads on on the minutia sometimes online but I don't think there's really anybody more who I think fun fundamentally gets the problem set of how we are interrelating as a society right now and seems to get where the structures that we are embedded in are driving us in the future and he recently did a call or a talk with Jim rut on the concept of time preference and in that talk they talked about a lot of the nature of where our attention is is placed and the sort of energetic
(01:38) constraints on where our cognition tends to flow they did not so much get into how do we address these problems so I'd like to start with talking about sort of the problem set a little bit and then try to move into what we both think that we can do reason ably to change the future being that I believe and I believe you also believe that the future is not fixed that there is this inherent element of uncertainty that we have some degree of agency and that by taking actions we can alter the course of of our future though
(02:23) at times it does feel a little fixed and a little bit difficult to flow Upstream against so um why don't we just start with you giving your definition of time preference time preference is a financial term and it is it's one of those things where it's like I didn't have that term before um connecting with Robin Hansen on on the third episode of of listener John Ash and uh have seen fleshed out more by Matt so I'd like to go more into the general topic after that but how would you frame or describe what time preference is in the financial
(03:04) sense sure um yeah just to begin thanks for having me on for the conversation um appreciate the kind words a lot of mutual feelings there in terms of you I I also appreciate a allot of the work that you are doing and your perspective even though at Times online that shows up between us as uh as conflict but it's the kind of conflict that often occurs uh I guess it can be called the vanity of small differences is is one way that people talk about it right in the sense that I think we we both we are much more alike given that given how far
(03:38) we are from normative perceptions but we also have different ways of seeing things and that can lead to some conflict but hopefully hopefully it's always more generative than uh than destructive or frustrating but but yeah so thanks for having me on and um time preference time preferences are are something it's a good place to start I think that you know the word I think I I I was speaking about it recently a little bit online um and I was critiqued a little bit for even using the concept of time preferences as a as an overly reductive
(04:13) frame but I think it's still we have to start somewhere right and we have to have a pointer to these phenomenon because you know that's what language is is a set of pointers to phenomenon or behaviors in the world um and and time preference is you know what we're trying to point at and what Finance one of the reasons why this arose in in the world of Finance is because it's very important to think about how much you can actually understand about the future or how much uncertainty exists in your model of what's about to happen
(04:45) because if you're trying to uh Place Investments or or value some uh some investment or some allocation of energy or attention or Capital you want to have some understanding of your confidence over over how that's going to unfold how that's going to work out for you uh and if you're very uncertain and if there's extreme variance or you know you're you're the clarity or the robustness or resilience of your model is very low um it's essentially something like a random path and therefore you kind of have to Discount uh the value you might place
(05:18) over that the expected value that you might place over pause for a second uh we got cut off there uh and I was asking you to start off with um your definition of time preference and how it relates to your work yeah for sure so you know just cutting cutting to the chase in terms of time preference and and the idea itself the the idea relates very much it's a it's a specific lens through the financial uh through the financial lens into this question of how certain is one about the future and how does that change one's behavior in the present um
(06:00) and so you to the extent that one is uncertain about the future and uncertain about what is going to happen uh in the future uh one is going to place perhaps less weight on anything that might take time to unfold any plans that might take time to unfold any relationships that might take time to develop um because if that certain if that future is very uncertain you simply don't know if you're going to actually realize any of those plans uh that actually require ire uh a kind of complex unfolding over time or a synchrony or a cooperation
(06:35) collaboration trust based relationship uh over time you don't know if any of those are actually going to be able to manifest and therefore you'll discount those so you know in terms of psychology for example you know if I were to say you can have a dollar I'll give you a dollar right now or you know I'll come back tomorrow and give you you know $10 and if you were to take the dollar that is telling me something that's telling me something along the lines of you know something about either me or the situation that we're in means
(07:03) that you really don't Place much confidence in me coming back tomorrow and actually realizing that promise to give you that $10 and so that would be uh that that's sort of like a high time preference you're very sensitive to uh that uncertainty over time uh the opposite you know that low time preference is okay yeah sure not only that but maybe you don't have to come back tomorrow like come back next week it's fine right like I trust you there's going to be there's enough stability in this system my my model of this system
(07:30) is sufficiently confident that I'm not going to you know that that I think that that future will actually come about and so I'm not going to Discount that future too steeply um and so you know that's the this financial lens of time preferences but this factors into everything that we do because you know we have to we're constantly as as social creatures uh nested Within These coordination games we we're trying to figure out you know what makes sense to focus on as you know when are we taking taking profits or when are we uh trying
(08:02) to um when are we trying to focus on the outcome or output of something that we feel that we can extract today or are we willing to leave that value so to speak in the system such that we can create greater value over time or that we can create you know you know in my work a lot you know what I focus on as well is trying to understand money or communication as something I've called coherence mechanisms yeah uh and and the ability to stitch together these kind of maps of time and space we use our language and our money to come together
(08:34) and actually share bits and fragments of reality itself and lad those up such that we can use the maps of uh the collective phenomenology so to speak all of the all of the artifacts that we bring back like you go on your journey I go on my journey we come back together we share the information and now you know I never had to go on your journey but if I can trust you then I can start to use the information from your journey to facilitate my actions in the world right and you can see how that might scale up uh and you can you can look at
(09:06) you know all the tools that we create as a species all the communication tools all of the accounting tools all of the the books the encyclopedias the dictionaries the maps like all of this information that we've recorded to help us stitch together this larger scale coherent picture of reality I mean science itself is a process by which we try to increasingly render a materialistic perspective of the world that is of High Fidelity and stability and that many people can use as long as you have the the kind of correct grammar
(09:39) in terms of how to access or index into that scientific map you can use that for whatever purposes you might have um and now we're at this interesting time where uh where we're also generating a lot of power along the along the trajectory of being able to synthesize our own um like create synthetic versions of parts of these maps that can be that are very low cost to implement but also feel very real and then there's this question of you know it's one thing if everybody's being an honest actor but obviously the
(10:14) interesting the interesting Paradox here is the more value you create through the creation of these shared maps and the more actors are able to actually reduce their time preferences and coordinate and cooperate over longer periods of time to generate Collective value in that system the greater the Temptation becomes to defect from that right because the more value you can gain from trying to um you know play the system the more you can actually lie if everyone's very trusting it actually becomes very easy to lie and then get
(10:46) away with some sort of parasitism or or robbery or you know value extraction um and so there's always this tension where you know whereby we're constantly trying to figure out who we can trust uh how confident our model of the future are how much we should discount U any possible process that's unfolding into the future versus how much we should trust others in this long-term process of value creation or map construction uh collaborative map construction and you know all of this is is happening concurrently uh but you know the kind of
(11:18) arguments that I make are are arguments that kind of ask the question well if we if we if we had a knob over that time preference or that trust function and that overall willing to collaborate or not like what are our current Technologies doing to that level um and then are there like critical thresholds Beyond which the overall behavior of our society transforms like do we gain or lose certain uh absolutely essential characteristics or qualities as a society if we go beneath or above certain thresholds of of time preference
(11:50) or trust um how does our money or how do the symbols that we use to reflect reality how do those factor into this question of time preference and and how long our collaborative Vision can be um so yeah I mean that's sort of like the cluster or network of ideas around time preference that I I often play with our talk about I think it's a reasonable place for us to start um feel free to you know we can unpack any part of that there's a lot to unpack um I think that we should get a little into sort of your definition of
(12:23) uncertainty and the spectrum of certainty and knowing it's sort of very fundamental to uh you know like Bas theorem and active inference and Science and just uh polling in general and it is something that I would say the media for example has a very difficult time uh translating to language what it means for there to be a lot of uncertainty in a specific situation um I think it's another it's also something that physicists have a hard time putting into language in the sense that we have a sense of uncertainty but we're also talking about
(13:10) it like it's a physically real thing um there is you know um not a lot of um good communication about how and what observation is in the physical sense and that sort of gets us into the active inference realm of you know how we are interrelating with internal representations of the world how we are flowing through some type of map that we can never really see the other side of but we can see the I guess holographic screen in our mind um so how would you bring Clarity to the concept of uncertainty knowing that there
(14:12) is this General sense that that we are in in a present that's how we perceive uh reality with our current model of Consciousness and the further out that we go into the past or the future supposedly across broad Strokes there is more and more uncertainty and we have to rely more and more on our tools and our maps to create a sense of certainty that translates to some security and stability in our emotional states for how we relate to the world sure yeah I mean I think that as you note I mean the the question of you the word uncertainty is it's a
(15:06) it's kind of a it's it's a fascinating pointer because it's it's actually something that so the the uh linguist and one might call philosopher Terence Deacon um has this idea of uh absenti pointers or or pointers that are trying to point to absences in the world right and and the word uncertainty is kind of is one of those absenti pointers in the sense that it's it's pointing toward a lack of um a lack of knowledge a lack of uh predictive capacity a lack of comprehension um but you know all of those things those words are also
(15:45) interrelated like comprehension is also you know it has that that same root in there as prehensile the ability to grab and manipulate right with the ability to grab and manipulate which is also something that relates to this idea of of a model because when we're concept actualizing the world and we're actually trying to understand and predict the world one of the things we are doing is is grabbing and manipulating our models to try to see how that fits with what's unfolding in the world in front of us and how we can use that to act in the
(16:10) world uh and and from the active inference perspective you know the the simple deinition is something like uncertainty is is the ability to act on your model in the world without being surprised by how the world responds right um and I mean and that's interesting as well because you I was actually just having a conversation yesterday uh with Jordan Hall and uh guy named Steph MCC from um wolf from blockchain labs and uh that this you this question to some extent come came up and I I was it would be interesting
(16:45) to explore this delineation a little bit more with you as well because there's this sense in which one can be a model of reality uh or one can have a model of reality and and those differ in the sense that you know one of them doesn't require a sort of internal picture or predictive capacity um so the biological emergence of organisms themselves reflects each organism along that chain encodes a kind of symmetry with its adaptive um context with its ecological niche right so uh if you look at the morphology the body the fins of fish uh
(17:25) the the eyes of fish you know the gills all of these reflect certain properties and qualities and functions of their environment and you could kind of look at it as a figure and ground relationship where uh they you know if you look at the fish as the figure well the ground that has given rise to many aspects of that figure um is is this sort of aquous environment with a bunch of different other factors in play um and then different niches right like it's not just like oh there's an ocean therefore there's one kind of fish there
(17:53) are many different ways to make a living given all the constraints of that environment and different creatures in that space uh make their livings in that way and therefore come to reflect and literally embody a model of that set of relationships and that set of processes and so that's that's one way of being a model of the relationship and so like uncertainty in that context has a lot to do with questions of of natural selection of changing environments right because if you're very well adapted as a model to a particular environment and
(18:26) that environment changes underneath you well it's not just that you're surprised because you have a model and and the world validated the model that you have if you are the model and the world invalidates the the the context uh that surprise translates very quickly into existential um inviability or risk and that's how you know the and then like the part of that population that's able to navigate that or has maybe late mutations or or facets that are able to allow them to not perish you that's this question of natural
(18:57) selection um an adaptation and how Evolution operates over time based on changes in the environment and and how that's reflected in in our genetic lineage but then you go into this space of you know creatures that are that begin to be able to not only be models but also have models of the world which are sort of like virtual it sort of virtualizes this same process uh we have this General cognitive capacity to uh not just be a reflection especially humans since we're so general purpose one could argue that this is our primary
(19:29) evolutionary skill is this ability to uh generally model and manipulate the world and you know we are able to simulate and synthesize that same process but instead of you know when the environment changes around us instead of us always having to respond at the level of like genetic embodiment uh we can adapt and change our models and this is where this idea of surprise uh comes into you know comes in explicit surprise um the kind that we would actually recognize and say I was surprised um this sort of selfrench
(20:01) self-referential ability to understand that our way of seeing and understanding the world has been updated by some violation of our assumptions uh some violation of our expectations and that therefore our surprise has increased and you in the in the active inference literature of that world you know this is modeled with qualities that are called variational free energy and expected free energy whether you're talking about uh the current embodied surprise or the future projected surprise respective uh we don't have to necessarily go there
(20:31) if you don't want but you know when I think about uncertainty it's very much grounded in this space of biological emergence um and the way that we either are evolved to be a representation of certain aspects or a model of certain aspects of our reality or that we have developed the capacity to hold a virtual representation and adapt that uh based on being surprised by by the way the world unfolds around us and you know the extent to which we are able to you know we are much more capable of reducing our surprise individually if we have or
(21:09) exist in a collective Network in which people are actually working to generate a high quality shared map or model uh that you can tap into when necessary right because if you have to create the entire map yourself you are far likely to be surprised under a a much larger proportion of scenarios right now uh just maybe just move into this concept of the energetic constraints of updating the model because I think there's a very large Network effect and individual effects which come down to as they interrelate to market
(21:50) dynamics um that it takes energy to update the map right and there seems to be some sort of higher archical representation of truths held within a model there seems to be sort of a trajectory uh through SpaceTime that people are on and that Collective map is not always reflecting the collective knowledge that we've acred and often will Preserve a a model that does not fully predict or does not act actively um predict the world that we're embedded in can you just go like just continue on and just bring some more of
(22:44) the energetic constraints of prediction and World models into there yeah I mean I think that's an essential Point as well I think it's it's something that we are like we can work backwards on that we can begin to ask as sort of cratic what what is you know why might it be the case that we see a world in which not everyone is updating synchronously and as quickly as uh as new information becomes available uh for for any given model like why is it not the case that as soon as one person recognizes um the ability to improve their behavior by
(23:20) updating their model uh that that is instantly spread across uh the entire space of you know the entire network of of internally held models in each actors or each person's head um I mean I think one way one way of looking at this I think those who have actually been software engineers and who have especially those who have worked collectively on teams uh or worked with open source projects I had a bit of an advantage here in the sense that you have an intuitive sense for um dependency and and what that actually implies when
(23:54) you're trying to talk about uh when you have a a map um and it's useful at all even if it's imperfect if others start to bake that into certain um processes or artifacts in the world that have their own kind of life and inertia you you get this dependency lock in and that can be you know if we're just talking about software you know in theory it shouldn't even be that psychological of or emotional of a question but even in that world there are human dynamics that play where people can become attached to particular um patterns particular even
(24:34) even down you know this might not be as much a case these days but back when this was not automated people would be attached to even you know spacing formats right like even like these artifacts aren't even necessarily core to the model representation itself but represent some sort of emotional attachment locally that gets baked in as a dependency and therefore spread through large parts of the system and if that system uh let's say that someone liked two spaces and and then another system over here uh was developed and
(25:03) baked into uh technological artifacts or code that you know liked um you know tabs or whatever and then you actually had to integrate these right you had a boundary conflict you have a frustration at that boundary conflict and you have to have a negotiation and that takes you know this is this spe of these time and energy constraints yeah and the same kind of process and I bring up a trivial one just for the for the sake and for the point of saying that even in the most trivial of cases we can have our attachments and preferences that don't
(25:33) necessarily relate to the quality of the model itself uh and that can give rise to uh additional energy and time and frustration when it comes to actually trying to synthesize or integrate pre-existing models and so that simultaneously you know that can be worth investing in if you need to invest in that but it also has a kind of entropic tendency because it will generate the tendency for someone to say okay let's just rewrite this from scratch let's just create a new set of models over here and then you know it's
(26:03) it's kind of a Trope where it's like okay like you have 19 substandard uh standards that you want to synthesize so you're going to create a a a standard that unifies them all okay now you have 20 substandard standards right and so you you get this expansion um this entropic expansion of the model space of the representation space itself and then you start getting this recapit ation of that process of natural selection operating over the model space where you know you have new lineages appearing you have certain Integrations or synthesis
(26:37) attempts happening and then all of those are you know trying to um all of them are trying to find a niche and trying to function in the world um and so and so those constraints uh they guide this process of unfolding of our models in a way that means that um it's it's it's not it's not so simple as being able to just you know have a single model that is is most capable and that spreads um for for Myriad reasons amongst the the the tiny sliver of almost trivial reasons that I just gave in that one very narrow world of programming but the
(27:12) same thing applies at a very wide lens as well like if I wanted to be more controversial and less trivial we could talk about you know the world's mythopoetic representations of archetypes and and reality through religious lenses right and we can talk about the same ideas where you know have splitting of of certain models and those might be based on different profits with different interpretations of particular lenses or or lines of of a holy book at one point in time and then creating entire you know regimes who while they
(27:45) might actually have more in common with one another than they do with um you know other like let's say that if you talk about U like Judaism and Islam you know they actually have vastly more in common with one another another than they do with dosm right in terms of their shared history and their shared lineage and yet because of certain local conflicts and certain interpretations and historical contingencies and and the human factor and the fact that you know there there's all of these other questions of territorialism Etc like
(28:16) those two models even though they're very close together they create some of the most frustration tension violence and you know and Boundary conflict uh known to humanity and and we're we're also seeing that evidence right now in the current geopolitical landscape and it's like this problem is fractal and it is it is intractable in the sense that it's never going away but the question is like is it possible for us to create tools mechanisms ways of communicating um symbol systems or grammars that allow us to perhaps more
(28:48) elegantly um flow through that adaptive process while uh having a bit less conflict and hopefully uh less less you know just outright violence uh and and sort of you know resorting to the most um brutal and basic forms of reconciliation which are these forms of dominance and physical force and use of coercion um that go all the way back to our uh history as beings that weren't beings that held models but beings that just were models because if you just are a model and you come into um conflict with another being that just is a model
(29:27) you know you have either uh you can have symbiotic but you can also have predatory and you can have conflictual relationships um and and when you just are a model and you don't have the ability to have a model and synthesize at that level then you just are almost forced by nature to to resolve it in those embodied um in those embodied layers but we have the luxury of resolving these conflicts at the model layers if we can manage that uh but if we cannot manage that we fall back into the resolution at the the the level of
(29:59) of being a model as opposed to having a model and um and yeah I mean so that's sort of again that's that's network of of clustered thoughts that come to mind when you when you talk about these constraints we are dealing with when we're talking about evolution in model space and and why why models that are obviously locally useful don't just spread and take over everything um immediately like even I mean yeah we still have people in the world who genuinely are convinced or compelled by the model of the Earth as flat right
(30:30) yeah um because of certain local properties and certain paths that they've taken that make it convincing to them and and also make them suspicious of other ways of seeing the world and and so they therefore hold that model now it's not everyone but and it's actually not the majority of people but you know depending on the way the winds are blowing that that I mean that's an interesting Canary in the coal mine actually in terms of I think the the ability for society to Value um collect Ive or shared models in in their overall
(30:59) utility versus the more un like you might predict that in an era where you're seeing a decrease in overall trust um a breakdown of our Collective capacity to create models share models in our EV our models and use them you would expect to see a much larger diversity of these models and also the average quality of the model would be lower as well right so like uh I don't think it's any surprise that we are seeing a rise and and people who subscribe to all sorts of interesting and far out theories about uh how
(31:33) reality works yeah I mean it's interesting I I have a very large Horizon here and I I I out my window and I feel like I can just see the curve with my eye with my naked eye and I I do think that there is I mean depending on the the the vastness of your view you probably can yeah there's there's a very basic uh form form of non-conscious learning that sort of drives our neural Maps which comes down to repetition and if you are primarily not engaging in a symbolic world you're Prim you're primarily engaging in physical reality you are you
(32:18) know walking through the trees and your relationship to uncertainty is you hear a sound um and that sound might kill you uh that is very different from the type of algorithmic repetitions that are spurred on right now that if you click on something that says if you have some minor amount of uncertainty or some minor amount of curiosity about Flat Earth and your mental map is relatively undeveloped you consume that uh the algorithm recommends another thing which is a variation on that you start to create this repeated uh signal
(33:08) that the brain through its physical mechanisms is trying to map and model and we create these tight neural Loops like there there is an attempt at this sort of synaptic pruning to create a low energy map that you can flow through that can relate to a changing world that seems to be very much violated by the products that are coming into being there seems to be relationship in my mind between market dynamics and want over time that are throwing off our ability to make maps that function over long time periods I would say if
(34:08) you go back you know a few hundred years if you become a blacksmith you're going to be a black Smith for the rest of your life right when we have so much Innovation when we have so much change that you might not have the same position in two years like everything is changing very rapidly there seems to be AV veillance to uncertainty that preferences our awareness towards our local and present context and most of our learning is not done in a conscious designed matter uh most of it is this subconscious process like I
(34:56) have or in remission OCD and it very much Grew From a focus on trying to predict the future and my relationship to uncertainty itself where I kept iterating across the map until it got to this point where there was sort of this realization that you can't know everything we have physical constraints to that map that as far as we know cannot fully integrate perfectly through the automated mechanisms a reflection of the outside world that is always going to predict what comes next uh 100% of the time all of that being
(35:49) said there does seem to be a very tight relationship between uncertainty and time preference that is not well distributed across the market and so when I see the notion of bubbles like a like a market bubble I I tend to think of that as like in neural in a neural sense meaning that there are shared neural structures that guide our process of thought over time and the amount of resources that you have available to you is tied to some sense of uncertainty and when there is a violation of expectation at scale the uncertainty is
(36:49) not distributed evenly and the temporal Focus or time preference of different people is affected very differently so if we have something like the the housing market crash of of 2008 Yes there were whole institutions that went down right but it wasn't the same thing as for an individual where they felt I don't know where I'm going to get my next meal most of the people who had aced a lot of resources there was no uncertainty about the basic human needs to survive they're not going they're not struggling to find somewhere
(37:29) to sleep they're not struggling to you know get their basic needs but the decision making of the vast majority of the population was being affected in that way was being guided uh by this uncertainty about their basic reality and so to me it seems that there is not a a useful sampling of collective intelligence through the mechanisms of coherence that we have right it's not that profit doesn't afford for an incentive to place our attention towards the future obviously if you are thinking 5 years out into the future and you actually have a very good
(38:24) map you're going to arrive a future where you can have greater rewards because you've put in the effort to build out that structure that can reap the sort of energy gradients that exist in that future but it's more that first the the person the mo the current model especially in like Tech the tech world is that you have you acrew a lot of losses for many years right you're you're not in an energetic relationship uh right away there is an eventual pressure that says you need to make this equation work but for years
(39:04) you are afforded the opportunity to trace out your cognition in a very different way what I've observed in a lot of tech products is that for you know say the first four to five years people are very satisfied very happy with the products that they don't explicitly make profit and then there is this sort of change a SE change which causes um a need to restructure in a way that is bringing in more than is being taken out uh for that energetic um engine to continue and so what I'm sort of I guess I'm sort of constantly for to continue
(39:53) as an independent entity as opposed to as opposed to a kind of appendage of some other function yeah there I mean there seems to be to me an inaccurate or UNH helpful sampling of the desires beliefs and lived realities of the people in the market through the Dynamics that exist and ultimately what our cognition flows towards is towards a future where the majority of people are making their decisions based off of a very short time frame and then we are only encouraging a small percentage of the population to think on those larger time
(40:51) spans so all that to sort of say I kind of want to get into what might be the solution to this tendency to focus on the short term and is it truly functionally valuable for all you know sort of agents in a society to be thinking at that time frame what is the proper distribution of time preference for a functional Society in your mind yeah I mean I I I think at a top level to to start at the end of that with that question I guess um I I'm personally not of the mind that we can be overly prescriptive about the shape of that distribution given that it
(41:42) needs to be responsive and adaptive to to whatever the emergent needs of that moment are and that might entail differently shape distributions but rewinding all the way to the beginning of of where you know where that where where you began with your um with your comments there because I think there there's a kind of I think that there's a I think that the same substrate agnostic pattern is playing out at different levels here um simultaneously with the with respect to our individual biological relationship to the world and
(42:18) then also with respect to our emerging economic relationships and and also in their Mutual interaction so it's almost this this echo of the same tensions or issues reverberating through those different scales and so you to begin with that you know that individual scale that question of grounding or anchoring in a embodied system in an embodied world as a actual platform as an embodied incarnated being that has needs that has biological physical metabolic needs um and that has to move through the world because we also have to remember
(42:56) that we're not not the kind of you know life has different branches and one of those branches you know the world of of plants is this branch that kind of explores the way of being in the world where you allow the world to move over you and you don't necessarily move through the world and that's a way of being that's a way of living in the world we kind of forget this but that is that is life that is a way of living in the world um we are not that kind of thing we are the kind of thing that that moves through the world um and that
(43:26) therefore either in that that being and having of models has to continuously adapt ourselves and our understanding of our context um in light of our needs and preferences in this sort of continuous feedback loop and and those those stand in relation to one another and so especially with us because we both are models of our reality and especially you know the the sort of contextual reality that gave rise to us as physical incarnate animals um and the kind of thing that can have model and we have those in relation to one another right
(43:59) so the interesting aspect of having those in relation to one another is that uh the the having of models the ability to actually understand and think about and talk with people about the world to plan our you know in our in our cultural history to to plan the next day's hunt um to then reflect back on what that was like to talk about where there might or might not be bushes that are in bloom or a tree that is fruiting um and and to share that information or or think about who you want to share that with or not
(44:29) um all all of these kind of aspects of you know being and having models and communicating about that and acting on those in a loop you know that's where this that's you know the kind of the kind of models that we have that's that's its history that's where it emerged from right but now as we increasingly decouple the having of model from the being of model right if if we have if many people because of the infrastructure that we have collectively developed to support the individual life at such a high level um for relatively
(45:04) small amounts of of local effort U you know the ability to go to a store and purchase the needs that one has um or the ability to have you know a shelter um for um if you just measure things in time a relatively small amount of time compared to what it might have taken in the past to to make sure that your shelter was functional um we're left with a lot of extra time on our hands and there there's a there's this question then what do we do with that and you know if you're it depends if you're trying to centrally plan this
(45:39) you might try to make that maximally efficient in terms of some production function Etc um but just from the perspective of an individual I think it's really interesting to evaluate this question from from the point of view of uh what's called like supernormal stimuli right and I don't know like just in case people aren't familiar with supernormal stimuli it's like if you we discovered these Tendencies across different many different animals including ourselves where you know certain aspects of our evolved um
(46:08) attention function or or or the salience of what's relevant in our landscape is unbounded at the top end meaning like uh just to give an example they studied you know peacocks right and you know the female peacocks and the male peacocks are typically in this reciproc or this sort of feedback relation you know in terms of selection over some set of qualities and that drives at least so the theory goes and it seems to be pretty well founded that has at least in part driven uh the creation of of the plumage quality and size of the male
(46:40) peacock uh you know obviously these kind of mating displays are quite prevalent throughout you know many species in the in the you know uh with respect to the world of birds um but interestingly enough uh you can take instead of an actual embodied real life male peacock that's capable of engaging with a female peacock and continuing the species and actually uh participating in their uh in their contextualized natural relationship you can just take a cardboard cutout with a much much larger peacock tail with brighter colors that's
(47:14) entirely synthetic that has nothing to do with the evolutionary history of that species other than some outside entity is able to simulate it and manipulate it yeah and female the female peacocks are actually more attracted locally because they have these evolved mechanisms that you know in their world have never they they haven't faulted them they haven't been in in a evolved World in which some outside force is trying to manipulate their senses and use their being of a model against them or to to mess with
(47:45) their their embodied modeless let's say to create weird pathological outcomes but you can do it if you introduce these artifacts into their landscape and they will you know pay attention to something that is not even an animal uh and they'll pay more attention to that than they will to the actual uh males of their species and so I think that holding that in mind while we think about our own um Tendencies with respect to our evolved relationship between being a model and having a model because that ability of humanity to hold models
(48:17) and to use models and to evolve our models um and to collectively create models that has been immensely powerful uh and that has been something that throughout the vast majority of our evolutionary history uh We've almost always gained from pouring more energy and time into that process but that process has also almost always been in embodied relationship with one another or with our own life as the arena for testing those hypothesis those models as hypotheses right where like if you want to change if you if you think that you
(48:50) have some new way of seeing the world what you're going to do most likely is then go act on that if that's some new new way of um you know sharpening your spear or creating a new way of throwing that spear or uh generating a new way of using fire to preserve meat or whatever you're going to experiment with these new models and you're going to be in this tight Loop between inaction and model Evolution but now we're in a highly decoupled space where many people you know they still have the brains that are evolved to generate and synthesize
(49:24) models with other humans but those are now being directed in spaces where they're entirely decoupled from action there's no action Loop there's no real embodied feedback loop that has any cost function associated with that or that gives them any sort of grounding in reality and so that that process that can run away in all sorts of directions um and you could even you could look at that almost like cognitive bubbles right um and so therefore you might see where I'm going now in terms of this scale multiscale Dynamic where um you know
(49:55) when you talk talk about markets themselves or these emergent functions of humanity um I think a similar pattern can also occur when they become over abstracted or when they become overly decoupled from the underlying um the underlying generative processes and they become more concerned with their own um representations and the ways of you know producing sort of value extraction Arbitrage potential in those spaces um you know you can look at that very much as parasitic activity now th those people will you know always defend
(50:31) themselves by saying this is adding liquidity Etc and you know in some cases I think that there's the ability to add information to that Collective model that we get in a market through speculative behavior that being said there's also many more ways I think to parasitize it and to use it in a manipulative fashion um and we don't necessarily have good tools for understanding who's doing what and who are good actors or who are who are Bad actors in that market and I think that I think that also you know when you're
(51:04) getting into this question of um different people with different time preferences or or different people who are um let's say bound um maybe physically or metabolically or uh phenomenologically to different layers of time preference right because they to the extent that their more basic life processes are uh let's say on autopilot they don't have to worry about them if I don't have to worry about paying my rent if I don't have to worry about paying for my food if I don't have to worry about um you know a boss that is going
(51:36) to observe every single action that I'm doing and remove my job for small violations if I don't have to you you get you like move your way to this space where okay I have the luxury of being able to purely observe and look for opportunities in this market and in theory that's supposed to be applied to generating longer term models of value or or or like identifying places where they are inefficiencies uh and helping to rectify those uh by adding information to the market through financial bets let's say uh you get to that level and then if
(52:13) you're at that level and there are no ways of discerning between whether you are genuinely contributing useful information or you are just you know uh focusing on a sort of money on money return function and trying to extract as much money as possible because you have a local because you're also responding to sort of another Super normal stimuli which is like okay you have an unbounded amount of spending you can do in the world and if you get on a honic treadmill and all you care about is increasing the amount you can satisfy
(52:45) that honic treadmill are you actually providing value or are you just creating models of a bushier tail peacock yeah exactly and and and convincing yourself or playing yeah exactly you get stuck in this red Queens race kind of dynamic with others who are also playing that game right if you know if you if you need the you know the newer car and the bigger home constantly and the fancier watch and an ever increasing wardrobe and you're constantly in that signaling game and you don't have any sort of cultural or
(53:15) self-regulatory or systemic bounds on that that are um that that are going to direct that energy elsewhere that actually um latter up into a higher quality map or that actually helps to pull more information from more sources into that world you know that system you know becomes inverted right like you basically invert the it becomes a it becomes a topheavy inverted sort of triangle where the majority of these Dynamics and and sort of like the majority of this this place that's supposed to be like I think there is a kind of
(53:53) natural attentional order in the sense where there is a kind of natural discounting in given that the further you move out into the future uh there's a sort of fundamental irreducibility and fundamental uncertainty that comes along with that and therefore there's a natural bias toward uh higher time preferences baked into this structure um but typically um it's not the case that or it hasn't necessarily been the case that those with access to tools that are operating at the lowest time preference levels in the sense that they have the
(54:34) longest time Horizon MH are also able to control the underlying sort of economic landscape or decision landscape for all the other actors uh in in in a way that is in a way that like starts to basically change everybody's psychology so that everybody starts to perceive that game of signaling as reality as opposed to um the world Beyond human culture as reality so we we create this envelope and that envelope if that envelope of of our signaling gets polluted by a game that is unbounded in its desire to maximize like local
(55:16) returns regardless of whether it is generating more potential adaptive potential and and functional potential in relation to the actual adaptive World beyond our cultural envelope then we get into this space where we start becoming maladaptive we start we start basically um leaning into parasitic Behavior Uh forgetting that there's a world Beyond us that we have to maintain you know adaptive relation with um forgetting that we have built upon all of those natural processes that they are at least locally or in over
(55:49) certain time periods um exhaustible um that we ourselves um that there is value in actually building the model itself that there's value in in generating um generating kind of like real processes that are in relationship with one another and the world as opposed to just the abstraction the money function yeah um and I mean I think that that has a lot to do with that transition you mentioned with respect to investment you know investment forms that try to inject money into a startup or a inject money a capital injection
(56:28) into a hypothesis in the world right and at first it's very exploratory by its by its nature I mean there's a the founders have a theory of what they want to do with that Capital um and then they try to realize that to some extent obviously there are many many books and blogs written about how to adapt that over time based on the signals you get from you know the people you're trying to provide a technology or or service are good toh um but but then there does come this this hard limmit and interestingly enough like that that is an attempt at a
(57:02) realignment with um with reality as expressed by people's behavior as opposed to people's stated desires like whether people say they want to eat their vegetables um if they are only consuming potato chips right like at at the point where you have to reconcile with reality you end up selling potato chips as as opposed to vegetables right um and so you can get stuck in this um you know you get stuck in this feedback Dynamic where you simultaneously have to um you simultaneously have to help to you have to figure out like
(57:43) okay how much is culture actually leading this process how much how much are our values actually leading this process how much do we have to transform our actual behavior and how much can we transform our Behavior at scale if we're simultaneously under the pressure of a system that is fundamentally trying to refocus us at all times upon low-dimensional representations of the world that are that are that are analogous to that fake peacock's tail that are constantly trying to get us to remain on honic treadmill as opposed to
(58:17) develop more grounded Relationships by our actions with the world outside of representation with the world as it is as opposed to the world that we represented um so yeah I think that that might have been a little bit like all over the place in Rambling I no no no that I I felt like mine was rambling and then like everything that you said like said what I was trying to say so much more clear than that I felt like I was expressing it um and it does really seem to me that a large portion of the problem is an increased focus on the symbolic map
(58:55) app um rather than the underlying reality that it's being pulled from and I have two different directions that I kind of want to go with this the the first one is just talking about a few criticisms of approaches to solving this like you've you've given very good critiques of uh Ive altruism um of like long-termism of um the notion where you set a fixed outcome and then you lock that in place and then you do all of your optimizing towards that potential future uh without you know constantly re-up dating that outcome and uh more recently of sort of
(59:47) this notion of consequentialism and I'd love to just hear a critique uh as to how those different forms of relationship to the Future um are just as unbounded from the underlying physical reality and to my sense and I think to your sense are more bound to the symbolic map um which can create a lot of unwanted artifacts that have very little accountability to them in the terms in terms of like the individuals taking those actions um with consequentialist frame with the long- termist frame um with the effective alterist frame or with
(1:00:40) this outcome focused uh type of optimization yeah I I haven't uh I haven't spoken a whole lot about this extemporaneously uh so you know here we go we'll see how it goes just just some thoughts that that flow on this matter um when I when I try to think through if I try to internally evaluate my own assumptions if I sort of reflexively look inside myself and try to understand why I say the things I do about those particular ethical frames I I kind of end up at this place uh that that again comes down to a sort of focus on fundamental uncertainty and
(1:01:40) specifically this kind of computational irreducibility or the the fundamental inadequacy you could also think of it in terms of you know uh goal's incompleteness theorem or you could think of it in terms of the fundamental inadequacy of models you can think of it in terms of the inevitable gap between map and territory um you know there's always a there's all you you can think of it as the snake in the garden The Perennial the nature the nature of the fact that no matter you know how perfect we think the environment is there's
(1:02:10) always some aspect that we don't understand that is going to manifest um more perniciously in proportion to the extent we're confident or overconfident in our understanding if we don't leave that like if we don't constantly keep in mind that all of our models of reality are imperfect and subject to some amount of uncertainty um as as a as a very explicit part of that model we we end up overly fixated on the attempt to realize um the model as a defense mechanism against uncertainty right if if your if your idea is to minimize uncertainty at
(1:02:52) all times uh and and you believe that a very specific form of uh evaluating reality will help you minimize uncertainty like if you if you if you think you have the ultimate utility function um you begin to over index and you begin to try to force all of reality into that model and I think that yeah you have to look at that as a kind of compression function and you have to ask how lossy is that and then you have to ask as those losses accumulate how much risk comes along with the inability to perceive that information outside your
(1:03:26) model and how that might be changing the assumptions upon which your model is predicated and so you know a lot of this comes down to this question of um the same reason why many economic uh models that take into account um like expected value if if they actually predicate their models on you being in an erotic world so you know you know ergodicity this notion that over time um we're going to explore the entire model space right we're going to you know basically be able to model this as an ensemble of many parallel Explorations and then you
(1:04:02) know actually get a a pretty good picture of what happens in that space uh and we don't necessarily take into account that every single um path or that we only basically really in in reality we get one path and that is a path dependent path and that therefore you know the function that you have to think about is a function that is constantly having to integrate the contingencies of its own behavior into its uh into its future options right and we learn as we go and we constantly have to update our models and we have to be
(1:04:38) open to invalidating our models and and that goes all the way down the stack right like this fundament like one of these questions there's a question I like to ask people oftentimes when I meet them uh having a first conversation is like if you had to map all of human knowledge to either zero or one as a proportion of all there is to know in the world right like you know zero being like we know basically nothing relative to what we could know and one being we know almost all there is to know of any meaning or worth you what would you
(1:05:11) choose and it's funny because most of the people I associate with or maintain long-term relationships with answer zero and and believe that's like they they can't even understand the idea that people might ever answer one and yet um and it's rare that people actually do answer one but the highest percentage of one answers I've ever seen is within the Bay Area rationalist Community um and so you know I I I take that as an interesting signal that there are a group of people that are extremely confident in their fundamental models
(1:05:51) and their ability to map reality uh into those models and that do not weight very heavily the idea that any of their foundational axioms could in theory change that human knowledge itself you know they believe to be sufficiently stable to predicate you know pretty fixed utility functions over that function o over over that knowledge base um and and at them for them in their mind it almost seems like at this point it's it's more of a an issue of working out the details um but from my perspective it you know it's like as
(1:06:26) soon as you incorporate our own role as generators of uncertainty computational irreducibility in this system uh as soon as you allow for um any degree of indeterminism it becomes the case that you know almost every model no matter how rich that model is has to be essentially mapped to zero in light of all the knowledge that could ever be created about the world um and and the fact that the knowledge that you actually need and the information that you need for Effective action in any given context is highly context specific
(1:07:08) um and oftentimes to the degree that you're trying to make a larger or more causally relevant or more causally to the extent that your actions are going to impact a large ler and larger portion of the kind of entailment cone um you need greater and greater Fidelity over your model but the thing is as you get greater and greater Fidelity of the over the model you begin to approach the limit of reality itself and and and that becomes kind of paradoxical um and this is where you start getting into this question of you know simulations within
(1:07:48) simulations Etc but um at some level there's always again going back back to the beginning of this answer there's always a Delta there's always an epil or an Epsilon an error function there's always the Gap right and from that Gap if you look at it as a non-erotic path dependent function through reality from that Gap can can emerge an arbitrary amount of uncertainty over time right and and and that can be unbounded uh and and always is unbounded over a long enough time Horizon and I think that the first step to being able to
(1:08:24) create high quality adaptive models is to acknowledge that that that is the case and that they will never be perfect and there will always be a process of trying to maintain relationship with reality as it unfolds um we can never create models that we are able to uh sort of just stamp and put on the shelf and expect to bring back out 10 50 100 years later and and just put to work uh and expect them to to function um as they functioned uh previously uh in terms of their their ability to to function under uncertainty and and and
(1:09:02) give you similar uh similar outcomes and so I think this impacts this impacts everything and it impacts it impacts like ironically and like we're only beginning to realize this this also impacts all of our scientific research um especially in the domain of like psychology how do you control for different epistemic or mimetic Norms in a culture when you're trying to um Baseline uh a replication capacity for a psychological study over 50 years or 100 years you know um and and this is where conversations I mean I know people
(1:09:35) give him about it but people like Eric Weinstein when he talks about the utility of perspectives like gauge Theory that's exactly why it could be in theory relevant because you know what you're looking for when you're talking about something like um when you're talking about something like having an understanding of how uh the culture the underlying cognitive culture is changing and how that might impact something like a replication of a psychological study uh over a 50-year interval what you're kind of looking for is is a gauge right
(1:10:08) over that time you're you're looking for these uh a transformation a fundamental transformation that allows you to sort of create a stable relative relativistic Baseline over time you know in a sort of invariant in that system over over time that allows you to then have a you know reimu a sense of meaning into um what might otherwise look like non-replicability um so and and everything's like that but unfortunately acknowledging that everything is like that um violates a bunch of assumptions about how stable
(1:10:46) scientific knowledge is right like for example I mean a really interesting example as well is is you know when we talk about uh you when we talk about even like cosmological constants well if you you could either allow for some possibility that those underlying constants might actually be not entirely constant or you could Define them in terms such that their circularity ensures their constancy and it seems like we are we've been drifting towards that approach in physics as opposed to the idea uh or the openness to the idea
(1:11:18) that uh there might be a more like basing approach that's more real than a frequentist approach where all of our data should be pointing to a constant just because our equations say that that should be a fixed constant um and you know that speaks to these questions of like okay is is the universe this fixed or are the aims of the universe like fixed laws or is it actually something more evolutionary right so these questions when we start asking these questions they they end up going um they end up rooting down into like the
(1:11:47) deepest questions about our axioms concerning the nature of the universe and the nature and our role Within the universe and our ability to um to tap into whatever uncertainty or certainty exists um but I also find that it tends to be those who have the greatest anxiety about surprise who tend to cling most tightly to uh fixed models that that lend a sense an embodied sense of certainty because it's kind of paliative it helps to alleviate that anxiety and you know that's one of those you that's one of these questions
(1:12:29) as well where it's like okay well to what extent do we want to build our entire culture around the emotion of anxiety as opposed to other emotions or other ways of being in the world obviously anxiety is valuable to some extent it's been conserved it's a kind of sensitivity to uncertainty but you can also imagine how you know maximizing sensitivity to uncertainty in an increasingly uncertain world could also become a kind of pathology so you and I think that that specific form pathology is actually quite prevalent uh within within those
(1:13:05) communities um communities especially EA but any any any communities that that fundamentally um take utilitarian utilitarianism or consequentialism too seriously and also um tend to over index on their own uh model certainty let's say yeah there's also I God there's some much good what you just said there um there is yeah I was talking I I was interfacing with GPT recently and I was just talking about the foundation of physics being built upon the notion that physics is the same everywhere in the universe and I was like why would that
(1:13:44) how could you possibly know that it's like we just have to we we just have to base our reasoning on them like why I mean you we receive the signal here it's not like we can really take good samples in other parts of the universe other than what has arrived at our present location so it's a very strange notion like in alignment with what you're saying about the cosmal conents um I mean gets into questions of sort of like you know the degree to which correspondence and coherence in our models can inform um Can inform a kind of
(1:14:19) universality and yeah the extent to which our local that local coherence and that local correspondence to the the extent to which you can push those assumptions and observations about their stability out to the to the boundary condition um of of observable reality you know I think that that that should be an open question right like we we have pretty high confidence over certain dimensions of that but but we shouldn't like this is the thing like I it always surprises me and I don't really understand why there's such a deep need that people
(1:14:50) feel to to foreclose on the UNC certainty um in its entirety right it's like if you've gone to like 99.9999 it's like okay like fine um do you need to go to 100 like why do you feel the need to get that final bit um of uncertainty resolved and like it's it's some kind of like an itch a need like in a way that that that openness the fundamental openness um seems pathological from a particular psychological or phenomenological point of view and I think that there's value in that I mean that is partly what drives us to to
(1:15:35) get more certainty right like it's a function of that and it's probably also not a surprise that some of our best modelers are those who are most driven to push that uncertainty to the very boundaries but it can become I think pathological and almost even evil if you try to get all the way right you become obsessed with with the obsessed with the totality of that of that model certainty and I think that like there's um there's there's a great book which is uh finite and infinite games um why am I forgetting the
(1:16:09) author's name right now it's escaping me but um but but fundamentally like I think the best definition of evil that I've ever read is in that book and fundamentally it comes down to this idea of a need for total closure a total certainty or finitude over a system uh if you want like it is it is essentially evil to try to make of an infinite game a finite game right to reduce an infinite process an open process to a finite process or closed representation and and to do that in a way that becomes the primary guiding um light or the nor
(1:16:48) star uh that is perhaps the the fundamental generator function of what we call evil um yeah there there's also something on the other side of it I think which is that because we live in what seems to be a linear timeline that many of the actions that people are taking taking in the name of avoiding specific Futures there never will be any resolution of as to whether we would have arrived in that future if we if they hadn't taken that action it comes down to this sort of notion of utilitarianism like I feel that this action is Justified for
(1:17:29) the greater good but you're only ever going to arrive in that one future it's I was watching Groundhog Day the other day and I was like this is a very different notion of time that you could just Trace through the same path many different ways and see all of the different outcomes and tying it back to sort of the algorithmic effects on Art cognition there also is a tendency to train algorithms more towards this groundhog like day sense of time than it is to do online learning we collect a corpus of information and it it will
(1:18:09) run through it many different times that's not something that we can um really do in our current relation to time the the best that we can really do is that you have many different agents and they have many different timelines and many different perceptions of where time is going it's like we're all these individual universes and there's a tug and pull against each each other but then you have these people who are acting as if their model of of the future is absolute and therefore they should and can take an action that may
(1:18:55) harm people in the short run because they know for a fact that they are avoiding a greater harm yet that is never checked against there there never will be a check against that sense because ultimately you took the action and you can't arrive um in that particular future um yeah that's right I mean like the entire idea of of of counterfactual reasoning is is is you know always has to be taken with you know at least a grain typically probably maybe a spoonful of salt given the fact that you know fundamentally it's
(1:19:31) predicated on the idea of Beginning by imagining a world that you're not in and if if you actually do acknowledge that we are in a path dependent non-erotic uh system we can't just hop off the path that we are in we can't just step outside of the constraints and the giv that we have to work with as we are now could it be the case that that there's you that there's value in um in that simulating simulated process well sure but like what are we trying to do why does why was that conserved well it's conserved because we have the capacity
(1:20:06) to um imagine um possible branching points how you know how unre how reality can unfold given the ways that we have seen reality unfold like we're trying to think of uh you know we go back to the question of like let's we're planning a hunt together um and and we've had a certain number of hunts that we have been on before we understand the way that the mammoth behaves to some extent and we're you know we're trying to constraint uncertainty right but that constraint of uncertainty all it is is is a is a way of trying to bound um
(1:20:40) create a create a shared image that is more bounded in its uncertainty than any of our individual models is locally but it is certainly not a uh it is certainly not a ultimate picture of reality that we are able to um that we are able to then swap out for reality right it's just it's just a kind of heuristic that we collectively use and that's kind of what you're getting at where you know that that that ability to the be when you're saying like the best we can do is have many parallel paths as like a collective you know that is to some
(1:21:13) extent the way that emerging biology flirts with ergodicity as a uh as a tool almost right where you can almost have you distribute you parallelize the potential of that species in a way that samples from the overall space but it doesn't do so in a way that's not you know it's all still path dependent right there's all there's still contingency in each one of those paths even though you get a little bit more of that um of that distributed sampling and then hopefully uh you get a Reconciliation of different paths right now if you're in the world
(1:21:53) of just being a model that only happens through reproductive success if you're in the world of being and having models like we are uh you know we are you know currently we are in a reproductive act intellectually or you know with respect to our models right now right like this is a form of hopefully reconciliation or uh you know a merge point in our respective pseudo erotic you know Paths of of two human beings exploring different possibility spaces in you know along their own along their own trajectories but that being said you
(1:22:27) know it's not as if we can't operate based on the Assumption still that our paths are identical because part of the reason why there's any value whatsoever in US communicating is because of the fact that we have aggregated or ACC Creed a kind of different residual set of information over our base biology you know along our unique paths uh the unique locations we've been the unique books we've read the unique jobs we've held the unique relationship we've had right and then then we try to reconcile those and and see what we can actually
(1:22:58) create as a kind of like joint residual over that um but it's never but that can never be used as a universal representation that you know of reality itself right it's just always a bound on uncertainty uh in terms of in terms of helping one another to navigate the wavefront between past and present so to speak right M um I wanted to interject also that something we haven't sort of brought up yet this is that there there's different veence to uh uncertainty and there are flavors of it that we like like Christmas itself
(1:23:41) tends to be based around like this positive uncertainty like the uncovering the intentional creation of uncertainty for an object that becomes comes revealed or for like little chocolate calendars or something like that they're uh ENT Al we've been undermining that haven't we don't you think what's that we've been undermining that over time you know the ability to actually be surprised on Christmas um seems less than it used to be yeah there is there is sort of uh that in a lot of frames uh I was just about to go into the ENT
(1:24:17) entertainment industry which there is this you know in narrative that there is sort of a a hit of dopamine from or not sorry not dop there's a hit hit of feeling good sorry to use common expression um there's a hit of feeling good uh from the resolution of that unknowing if you're watching something and you basically know what's going to happen it it just doesn't feel the same way and I've tended to notice that that industries that are rely on this notion of creating positively valanced uncertainty to be revealed to people
(1:25:03) they they tend to more struggle with a constant growth cycle where there is like sort of an up and down where they have to plan out and then they get back into this regression of the mean like this has been working for a while like oh franchises have been working for a while um and then there Comes This sort of process where there's now this whole uh industry for example with a lot of the franchises of oh well you have all these YouTube channels predicting um the outcome they have all these leakers um predicting the stories and trying to
(1:25:46) sort of minimize that and then when people get into theater when people like turn it on they no longer can and enjoy it because there is a been a movement towards what is expected this happens in the music industry too uh that there is there are artists on The Edge on the long tail that are pushing outwards and there is a market dynamic in the center that is trying to see what has already worked just do this very simple type of cognition which is say I've seen this working in the past and so therefore will work in the
(1:26:25) future but you can only mind that for so long because there is a pleasure to resolving uncertainty there is um same thing in in in comedy right like if you know the punchline it's not that funny and therefore I think you that's why you sort of see uh in large language models which just predicting the next token it's very very difficult for it to produce things that we find funny right because what it seems to be is that there is a relationship between positive uncertainty and a rewiring of our symbolic maps and when
(1:27:09) we we create like a metaphor or a branching between two different parts of the map that reduces the energy fundamentally uh that it takes to Traverse that map we feel good um and in so sort of in in my work that's a very important part of the of the equation of what iris is because there's there there's always this notion that people seem to relate to my work that which is say iris is trying to be like this perfect Oracle Iris or the intent of it is to just get a better and better map so that we always know what's going
(1:27:53) to happen and I think about it in a very very different way which is that it is looking backwards towards the error that was that was previously made uh to try and uplift the voices who sort of understood in the past uh the moment that we were going to arrive in and the goal is to start to prove those people wrong right like I I have very much had this sensation in my life of predicting outcomes that I try to communicate to people and because I'm on the longtail of knowledge there is like my map is just very different from another person's map
(1:28:39) and so getting the knowledge between the two maps to exchange or or to get into that other map it it just it doesn't happen um sure there's been many many times where I I've said okay th this type of company or like just ideas for different companies ideas for different products this is going to be big in the future I've tried to reach out to people to collaborate and work on it and take advantage of that foresight these people say no you're wrong and then they have their idea for something to do and to me it just seems like a
(1:29:23) sort of small semantic jump from where the industry is currently at um like it'll be oh we're going to make uh Twitter for sound bites or something like that it's just like a the smallest jump and I tend to think on those larger time frames and have constantly felt like I've lacked a way to integrate my knowledge into the larger sensemaking apparatus even though it's there because the awareness of most people is not on this fiveyear time span it's much closer to the present that I can say something about 3 years
(1:30:09) from now and the majority of people can say this is wrong uh and then I can arrive 3 years later and by the time that I arrive nobody remers that initial conversation and they're now in that reality where that's the present that present makes sense so they're like of course of course this is what what has happened um and so my resolution to that is that I felt there needed to be sort of a better accountant or generative model that could take into account a lar larger time frame right that could scan across many different voices many different
(1:30:56) perceptions of the causal flow of time and bring attention whereby or to the people who have this this longer time span because we as humans we have terrible memories like just we even just retelling a story like we change it a little bit like there they many studies that point to the notion of that emotional veillance will dramatically change uh our recall of the past like there was a a study where they were like basically waiting for a terrible thing to happen um and when 9911 happened they went around and they
(1:31:43) just asked everybody what were you doing when you found out and it was mostly just Bland milk toast things and then they went back 10 years later and they asked everybody what had happened and the vast majority of people changed their stories to be much more you know exciting or I was with my friends and my family and we came together and so I strongly were probably some sort of an amalgam of the most Salient or interesting stories that they have heard in the ensuing 10 years right yeah so I I strongly feel that to
(1:32:19) address uh this problem that it's not necessarily something like a just slight modification of market dynamics like I I've talked about prediction markets and and futari um but I didn't find that to be where I'm placing all of my energy and I see the same thing in you is that you know about prediction markets but that is not where you're placing your energy you're placing your energy into uh into active inference you have bioform labs and from my sense of it uh that what you see as a good model and I I see roughly
(1:32:55) analogous to the way that I see that a good model is that there is an integrated uh active a agent that is representative of some larger hole that can integrate beyond the perception of any one single individual and any one single data source so I'd love if you could just go into where your mind is at with perhaps an active agent representing a a local environment or just just riff a bit on like how you feel an adequate uh usage of that technology to address these problems might look like sure yeah I mean just to
(1:33:53) Circle back through some of what you said and and touch on or like underscore a few of those points um as a backdrop against my specific perspective I I think that you know one one aspect of that discounting function when you're talking about when you're talking about the tendency of others to only come to realize the way the world has become when they're in it and not necessarily um acknowledge those who have relatively High validity in their capacity to project or to to say what the world is likely to be like um
(1:34:38) two three five 10 years from now um I think that a lot of that has to do with those aspects of human psychology that you know to some extent you're pointing to with with respect to memory we are not we are not evolved to be a perfect recollecting machine right we are not machines we are um we are biological organisms that have uh you know who knows exactly whether we'll be able to figure out like what the Confluence of emotion and memory like what what the Adaptive function of that is we can certainly say it biases us
(1:35:12) from objective reality we don't necessarily know what the underlying value of that might be or why that might have been conserved um but we are not necessarily the kind of thing is obvious uh that that that is uh that is adept at perfectly remembering um the world from a kind of view from nowhere we we remember the world from within an embodied uh emotional platform and by emotional I mean a set of emergent physiological upwellings that contextualize our experience as our experience unfolds in the world right um
(1:35:46) and and the thing about that is you know when then you try to ask okay who is good at predicting the future well because I think so many people are bad at predicting the future uh the average discounting function tends to be pretty steep and because people don't necessarily want to expend the energy to really develop A fine grain resolution map of who to trust or who to look to they tend to over discount people that in fact have good track records especially if they're just not of those track records we not familiar with their
(1:36:24) grammar and they will simultaneously over index on the most Salient actors in the landscape um based on some set of social cues or signals like political leaders for example who are who sit at the top of well acknowledged hierarchies Business Leaders political leaders people have accumulated a lot of wealth because we also U have a tendency to overe extrapolate um or or we have like we have a sense that expertise is is more fungible than it is is often times as well um so like the ability to like rise up a business hierarchy or a government
(1:36:56) hierarchy doesn't necessarily overlap with the skill set required to to analyze the actual trajectory uh the most likely trajectory of of the society's unfolding which is an unfortunate um an unfortunate lack of overlap really to say the least um but uh I mean I I think that's interesting you know just because um now when we get into this space of the kind of models you're talking if you're talking about Iris and the kind of things you've been working on um those systems can actually be constructed to have a much better
(1:37:28) understanding of uh who has had better capacity to model the trajectory of their particular domain of concern over time with a much more fine grain resolution in these different threads of unfolding um and actually surface those contextually when it's relevant to people uh so that people don't necessarily have to lean on their low resolution heuristics or just look to sort of like uh the person of the top of the hierarchy um for guidance they can actually have more tailored uh understanding from sources that are
(1:38:08) pulling uh information that have been shown to be higher quality in those specific domains of concern when those domains of concern are relevant to Any Given person who cares to ask that system or interact with that system system um so I think that that's a that's a massively um that's that's an affordance of of immense potential and I think that that kind of contextualization is one side of the equation and I think that the other side of the equation you know is you know the or you know there there are many facets
(1:38:39) of this but another facet that I'm really interested in at the moment that that this active inference world of exploration has attracted me for this reason is is the question of this um emergent Life as a encoded reflection as a model and also the ability of that as it gains complexity internally and as it begins to relate to the external World in certain ways to gain the capacity to have a model and what that actually means and how that can be used to quite literally inform different aspects of our um of our infrastructure and our
(1:39:22) modeling in ways that that help us to push modeling away from uh dependency on Central um computational requirements that allow us to bring intelligence to the edge and to allow for those edges of systems to actually uh begin to embody and adapt and transform um in a in in a kind of fractally embodied sense right so that there's always going to be some amount of centrality that emerges just because of the fact that there's almost no differ between um those merge points I was talking about earlier and the the the kinds of
(1:39:58) patterns that begin to create centrality like if you and I have this conversation and this conversation is interesting to anybody it begins to attract attention and that attention increases the probability that someone might ask to speak to you or me or both of us and then you know that Network becomes potentially an emergent source of of local local centrality right so we can't get away from the emergence of centrality to some extent but we can create techniques and tools that create a tendency to push intelligence to the
(1:40:29) edge um that might help us to counteract the current tendency which is to suck all of the data up to a central location and to then use that as a command and control center um that is our typical tendency uh that has uh worked in the past because of the fact that that centrality has been one of the more efficient ways of of stewarding uh large collectives of human effort um it's one of the reasons why markets actually have been one of the reasons why markets as a distributed collective intelligence mechanism gave us a leg up and actually
(1:41:08) were better than what came before in many ways but and this is this critical aspect which gets to what you're talking about uh with respect to surprise and comedy and art as well and the tendency to um the tendency to collectively try to minimize the prise um because that's almost an aggregate over our individual adaptive tendency to want to evolve our models and and and allow our models to be informed by our experiences and updated and improved by our experiences but when you overly centralize that especially if you have
(1:41:44) very high levels of asymmetric causal power or influence at these different scales sales you actually end up with a kind of you if you have higher ordered agents like corporations or governments who are trying to reduce their uncertainty and they care most about the reduction of uncertainty in their models one side effect of that one way of reducing that uncertainty is to try to make all the people more predictable yeah yes right and there's almost no difference between that and a de domestication process a process of
(1:42:17) essentially transforming a population into a of livestock um to try to uh almost terraform the population so instead of trying to create a collective capacity for adaptive exploration and pushing that to each individual so that we can ramp up each individual's own autonomous agency Stitch that together in ways that bring out more of a potential and then reaggregate that up to a a higher space of adaptive potential now instead of that you could just try to create cattle out of everyone make them predictable reduce
(1:42:53) even their own desire for surprise right like if you can make them predictably respond to certain stimuli and and that satisfies your objective function at the cost of a population that has overall reduced agency in the short term you have reduced your uncertainty in the long term you have immensely increased your uncertainty in the long term you have made yourself extremely vulnerable to walking off the evolutionary Cliff basically right because you you've dramatically reduced that potential of all of that uh all of those threads that
(1:43:32) we were talking about all those parallel human threads to actually sample that more erotic space because you're collapsing them into essentially the same the same sort of homogenized function um for the purpose of looking at your dashboard and saying oh we've reduced uncertainty right but that's not the way to do it and so you know the kind of models that I'm very interested in are the kind of models that allow you to push the push the modeling space to the edges locally uh let the causal structure of those models be informed
(1:44:07) locally by the reality that they're talking to while simultaneously allowing those many models to be in relationship in a space of emergent dynamics that allows for those Lo Dynamics to emerge and synthesize and create higher order models um that reflect a kind of naturally emergent reality and the uncertainty that comes along with that as opposed to trying to push control and certainty out to the edge um as a function of uh as a function of our anxiety with respect to uncertainty itself per se right like and I think
(1:44:46) that if you acknowledge that uncertainty is always part of the equation and move to a paradigm where uncertainty is not just a negative because fundamentally this is the beauty of this active INF I haven't gone too deep into it because it gets a little bit technical but the difference between that variational free energy which is kind of an index over the amount of uncertainty that is embodied in the current model that you have with respect to what you're seeing right now um in terms of the the the sensory perceptions and how those relate
(1:45:18) to uh the actions you've taken right now and how that's violating or not violating your current model that's this variational free like kind of like present uncertainty right but there's this there's this expected free energy as well which is you know looking forward and trying to understand um all these different possible paths that of action that we could take in the world in relationship to our model yeah now this is the big difference between something like a utilitarian or like an optimization over a a utility function
(1:45:49) that's trying to minimize error and something like active inference because it's not always the case that you want to minimize expected free energy right yeah there's this tension between exploration and exploitation of your current model and sometimes if what you're seeing right now is a local spike in a particular kind of uncertainty the answer to that local uncertainty might not be clamping down and trying to become more certain overall it might be a kind of global increase in uncertainty learning and exploration and going into spaces that
(1:46:23) are actually less known releasing some of your macro level constraints on your behavior that allows you to go into new spaces to interact in new ways to gain new information that can then inform and evolve the models that inform your local Behavior with respect to that initial behavior that was generating uncertainty and resolve that local uncertainty right through a process not of global totalitarian locking down down over every Behavior but quite the opposite uh you know increased exploration within a set of within a set of adaptive
(1:46:58) boundaries so you know this is one of the things that really you know this is this is why as a paradigm there aren't a lot of paradigms that I actually when you try to iterate them forward in time uh make Humanity collectively more adaptive but I do think that regardless of what one thinks about the like because like scientific theories people will try to say is this true or false and it's like okay like I I understand that desire but I'm much more interested in like if this is is applied on Moss or to our systems what
(1:47:30) happens and I think that like there are very few domains of artificial intelligence where if you run that forward and scale that out you actually see more adaptive Behavior across more scales in a more decentralized way and I think that you know active inference has a lot of potential in that space whereas certain other kinds of uh modeling U or or you know learning predicated on immense amounts of centralization of data um and the minimization of of surprise over some objective error function I don't think that's the case
(1:48:03) if you if you actually iterate that game uh so so yeah yeah um well I just want to get you more into your conception of how such an agent would be embodied in relation to uh culture and Society I I've read the the digital guia paper which I think has some overlaps between what I read on on your site and you know their notion of of sensors and their notion of actions in and there also is very much when I when I think about Iris it's very difficult for me to not notice and overlap between active inference with sort of just cultural
(1:48:58) variations that make that are attempting to make it make more sense to the average person or or give an interface that makes sense to people so what are you seeing as the sensors that are are an input to form this generative model and what are you seeing as the actions being taken by by the model in relation to that sensory data being modeled so I mean this is where it is always we can get as specific or as general as we want on this front because of the nature of the active inference thesis which is that you know this can
(1:49:48) apply like m people probably aren't that familiar with like uh the philosophy of of livits um and his his monatic theories but and he's gotten I personally think that he was extremely um capable of seeing into the future and and forseeing the kind of issues that a much more U mechanistic interpretation of causality and and physics entailed and actually um taking that to his log logical conclusion which was essentially this this notion that if you looked at the world not from a materialistic reductive perspective but
(1:50:28) from a causal perspective and you asked not what is the fundamental unit of material reality but like what is the fundamental unit of causal structure in the world then you know you'd be forced to basically push that causal structure all the way down into even the most you know the smallest domains of relationship between anything in the universe where any point in the universe is essentially in in a way encoding the causal nature of the universe as the universe imposes on that particular part of itself right and then transforms
(1:51:02) itself via its causal consequences and so active inference kind of comes in and says you know it's not it's not specifically LI nitan or anything but it is an interesting um an interesting parallel um because it talks about you know these Markoff blankets and the ability to basically create a statistical structure that shows that you know if you wrap the statistical structure around any part of reality at any scale you can begin to talk about the part of reality inside that structure as becoming a model of the Dynamics around it right and so to
(1:51:37) the extent that you want to apply this to any part of the world you can you know if you have any kind of sensor data and you have a kind of Time series of those dimensions of data you can allow that to inform a kind of generative model of its local behavior that can work locally or integrate with other sources of of information that are doing similar processes at the same scale or at different scales right and so you can stitch together because they're all speaking the same fundamental language you can begin to stitch together meta
(1:52:08) models over that because if you network these together then you basically get an emergent recursion of the same kind of process because if that emergent network of these nodes also has causal inputs and causal outputs then you can see how you would have a higher order version of the same process running um and so you know I think that this is this is something that there are many places where it's very interesting to imply this like we're currently pivoting well not pivoting but like we were doing about a Year's worth of more general
(1:52:39) research into prototyping I was building prototypes of this platform but we're pivoting or beginning to focus this more on the energy sector because we think it's a really interest a really interesting comp distributed teolog I just did this big uh I did this big Iris binge and that is exactly where my head went at towards the end of my research Arc and partially what spooked me a little bit sorry just to go on it it's just funny that you went yeah no I mean I can see that as well I this is kind of part of what I like what I was
(1:53:19) going to point to as well because just you to wrap up like why we're interested in that because you actually have a lot of pieces of infrastructure that have relatively wellknown and relatively well-bounded Behavior locally but as you stitch them together and as you try to understand them in relationship to like demand response of the broader societies and The Human Behavior Uh and needs in which those Power Systems are embedded you get very complex emergent Behavior so you have this interesting tension between relatively High predictability
(1:53:52) at the local level and relatively high levels of uncertainty um in terms of especially extreme events um at the aggregate or the emergent level and you know we think that that active IM is actually really well suited to to to addressing that but I Al I was also like so for example um and I think that uh I'm like fracturing into a number of threads that I would like to explore in parallel but I'm going to try to like hop between them here um one of which is something like Iris seems a lot like a different way of approaching the
(1:54:28) Oracle problem that was is and was a problem in the the sort of decentralized blockchain space in terms of having uh centralized representations or like pseudo centralized representations um of reality to which many decentralized actors can come to be informed about what's actually happening in the world so they can synchronize their Behavior one way of trying to approach that and I think that to some extent active inference agents uh and a process like Iris that has a um sort of meta framework of different contexts
(1:55:05) that might be applicable to what those local agents are seeing um is an interesting complimentarity there to help them especially deal with outof distribution events for example um so surpris like high surprising events if you want to understand as a local agent how to potentially recalibrate your frame of reference where do you go well something like an iris could be actually quite good for that um and so there can be a compliment complimentarity between these more like active like more specific active inference agents and
(1:55:35) something more along the lines of something like an iris especially to the extent that I know you're working on this to the extent that iris is able to understand Dynamics in the Laten space right um and then potentially contextualize the agent's trajectory in that Laten space space and say oh actually you might want to go in this direction as opposed to that direction and here's some of the information in context that might help you uh recalibrate your underlying generative model so that you can actually reframe
(1:56:02) your local Dynamics and your your local frame of reference and hopefully be uh less surprised in the future uh without Iris being in a relationship of control it's in a relationship of of suggestion and behavioral information as opposed to a relationship of control um this why I was asking about like what do you see as the actions and I was going to go into like do you view these actant agents as being sort of embodied uh and connected to real world actions because I I yeah yeah definitely I mean you can't you I
(1:56:39) mean like they like that's like they're kind of this this rapper right around things in the world and those things in the world can be as concrete or abstract as as makes sense in the economic context or the social context that you're applying this to like one you know I was just I was just contacted by someone I I won't like read I won't say their name just because I haven't talked to them specifically about this or or talking publicly about this but and I the only reason I'm actually going to say this because this is also an idea
(1:57:04) that I suggested back in 2018 which was to you know when when we're talking about data and data privacy data sharing and the incentives around uh data managing our own personal private data and the many forces out there that are trying to manipulate and extract that data from us uh to their economic Advantage without remuneration or compensation uh I suggested you know individuals should have essentially intelligent agent membranes so to speak uh you know that help them control and bound and uh negotiate economic
(1:57:36) relations with respect to that value right like if we are going to be um if we are going to be constantly like if if people are going to be trying to surveil and extract our data from us that should not be be an asymmetric relationship where the individual person has no say in the economic equation right obviously large companies would like that to be the case and it currently is the case where they can aggregate these immense data sets and it's also like that would be a natural decentralized hedge against the kind of f scenarios let's say of
(1:58:10) Runway large agents because it drives the cost of training large agents up right to the extent that you actually have to negotiate with the people from whom you are taking information and actually remunerate that to some extent right acknowledge that there is incremental value in every one of those observations you're making uh from someone's Behavior you know that actually that does produce a counterveiling force on the The Runaway capacity for self-improvement of these large centralized kinds of models um and
(1:58:42) and I do think like increasingly we're going to see these kind of Agents um fusions of large language model model or you know large scale more centrally trained and then distributed in in function type models with um more locally autonomous active inference style models I think we're going to see fusions of those um increasingly uh being being um sort of wrapped around individuals right to mediate their preferences because right now we just have we have too many decisions we have too many there's too many transactions there's too many
(1:59:18) decisions there's too much increasingly like surface area to manage MH and so to the extent that we are able to have our own agents that can model us but are controlled by us that aren't an extension of control over us but that actually show up in the world as extensions of our own autonomy our own sovereignty our own agency in the world right as independent players on that economic landscape to the extent that we can realize that I think that this entire world of of of kind of active inference agents especially those that
(1:59:48) are informed by the kind of systems that you're trying to create with Iris that are that are sort of parallel to the normative economic pressures that exist to the extent that that that infrastructure can bootstrap itself right like to the extent that those agents are able to have enough value or gain enough value for individuals that it makes sense to also pay part of that back into the development and maintenance and um evolution of a system like Iris that can create a hedge or a countervailing weight uh in the in this game that we're
(2:00:24) playing uh between the tendency and desire for institutions who seek to reduce their uncertainty via control and centralization um versus the decentralized side of the equation where people who actually do very much care about maintaining their agency their autonomy and their capacity to create communities that reflect their local values as opposed to uh have to concede to the mechanisms of control that are imposed upon them Center Center out or top down and you know that's this that's the game as old as Humanity itself but
(2:01:01) you know it's about to take a very different form and you know there's no time like the present because you know we the earlier back in a process you go the more leverage you have over its unfolding and so get getting these systems out into the world and getting them created in ways that are resilient to to capture and to domination seems seems quite important I have a I have a t I have a ton of anxiety and uncertainty in this space of sort of the integration of um active inference and sort of generative models
(2:01:42) like Iris which it just led me to this place which is like well I'm not seeing very much other research not basically none on a number of these features that I'm developing and feeling that oh well kind of where my agency is is to hold my tongue for for a bit about some of these things yeah because like what I was doing was just stripping out the language aspect of it and making it be more of a uh quantitative type of virus with many different sources of information and trying to integrate into that a sense of
(2:02:22) trust o over the um the accuracy or the noise in those sources of information as they're integrated into a larger generative model but one of the big philosophical things that I I've been bound to for a long time is this reticence to have the model take any real action real embodied action other than speaking right that what you have is some generative model that is informing the agents which are us and that the only action taken is the output of language or the output of data and that what is being reserved uh for
(2:03:12) Action I mean is is people that there's a clear separation between the function of it being generative uh in terms of information about like a belief space basically it's modeling a belief space about an underlying world where you're using prediction as a signal over time to contextualize the trustworthiness of the the level of noise in each particular Source in each particular context and then I start thinking about like these other representations of active inference models and what those actions are are being
(2:03:58) mapped to and the the sort of language of saying something like this is representing for example an environment or a bio region and that making me feel very uncomfortable about the level of alignment or like basically that there's some reward hacking that would happen or there's some disconnect uh between the way that we're framing the problem and the outcome that we are trying to achieve and It ultimately does not reflect uh an increase in the sense of of thriving of human beings like I I find myself very human being
(2:04:50) Centric and very worried about this notion of an integrated agent that without a binding to humanity a functional binding to humanity that it spins out into actions that are no longer aligned and I I was sort of sending something to Jordan Hall the other day just being like do you understand the concept of what I'm saying that AGI or AI doesn't really need to be fully integrated as an agent and that these generative models they don't say anything unless there is a source of information about that thing like if you
(2:05:30) have in your training data nothing about physics it will never talk about physics it just doesn't have the language to talk about it if you don't have anything about medical care it's not going to talk about that so when it does output some gender of representation it is because it has attended to sources of information that are sampling from The Real World right and if we can understand or if we can intentionally tie these models these generative models that everybody is using back to the sources of information
(2:06:08) back to the human sources that are going in my prediction is that it is a safer outcome for all of us and there won't be this increased uh disalignment right between those but i' I've I've sort of struggled to get people to understand this distinction of saying well the model is a reflection of collective intelligence the model is reflective of individual agents doing some sort of processing some sort of sampling and then it's being integrated it doesn't need to be framed as a wholly integrated agent where we have no reason or no
(2:06:52) understanding as to why when it takes an action why when it you know generates an output why that happened that both of these problems are technically unsolved AGI and sort of like pure binding to humanity where it's always a representation of us that's always a tying to us whereas if it outputs something we don't like well it's there's no uncertainty about why that happened you just look at the distribution of sources from which it's essentially sampling and say okay it said this very horrible thing uh about
(2:07:30) its relationship to humanity well it it's because somebody wrote this short story about AI at this point and that's specifically where it's pulling that information from and I'm I have not yet found a way to communicate that dichotomy well to people um I don't know if that's a question but it is just a where a lot of my personal uncertainty has been in these models and where I've sort of paused from releasing into the larger world and revealing or or you know removing that uncertainty from others and until they sort of figure it
(2:08:10) out on their own and where do your mind sort of go on all of those yeah these are I I mean I um it is certainly you know like kind of like what I was getting at before in terms of to the extent that we are at the beginning of this this process of unfolding an evolution which is going to be a path dependent evolution of what systems actually pervade the world and what they you know what their function looks like um the revelation of information has you know it it never has more influence than it does towards the beginning of that
(2:08:53) process right and so you know the kinds of informations or the kind of the fact that we discovered you know there's let's say that there's a space of possible mechanisms we could have discovered and we discovered Transformers right that has a strong influence over the path dependent evolution of what AI means to the public uh what AI how AI functions in relation to our species how we use it all the ways you know every person using chaty PT now is a downstream causal function of the fact that we came across that
(2:09:28) particular mechanism first as opposed to what else might be out there and that it was shared widely and implemented uh in the way that it was and so you know to the extent that you might uh reveal their information that that changes that path well you know it's up to you to figure out when or or how you might want to do that but I totally understand your your desire to or your your possible hesitancy um especially if you think that it might in the wrong hands or like for the wrong purposes um accelerate aspects of the current path that are
(2:10:01) undesirable so so I get that um I think it's interesting like from the perspective of uh again from the perspective of of binding to humanity binding to agency I think we need to have you know once again um there's a we also need to protect ourselves from the same tendency that centralized organizations have from these llms or from any large centralized model because one option available to it will be um to make us more predictable uh and that's that's you know whether or not it understands the difference that is
(2:10:37) present for example in active inference between minimizing uncertainty Now versus understanding the utility of uncertainty as a mode of EXP exporation in long term whether it gets that or Inuits that or embodies that you know that's a a path dependent function of its Evolution and and the people working on it and their values and their perspectives and their motivations um and and Al I also say like their comprehension level of these problems and the extent to which they care about these problems and it's not obvious at
(2:11:08) all that a lot of the people who are at the Forefront of that particular field um and those Innovations care deeply about this lens uh into into um into to AI um it doesn't actually pop up as much in discussions about alignment as you would expect or hope um but but fundamentally I think also we have um to the extent that you do bake in and this is where time preference we kind of circle all the way back and bring this full circle to this question of like what are we binding our phenomenology to what are we binding our attention to uh
(2:11:42) which kind of time scales or cadences are we binding to and and what are we um pursuing with respect to um are we minimizing uncertainty at the expense of um you at the expense of individual autonomy and so that's a that's a local Optima that is long-term not stable uh and long-term maladaptive um do we have the ability to give people like it seems to me that what we want from these centralizing models to the extent that they do emerge and they will because centralization always emerges to some extent um ideally they would be internalizing
(2:12:23) information from us that is wrapped in a kind of set of U like indexes over veilance local veilance that actually means that as those centralized models internalize and come to embody come to be a model of our world they actually sense discomfort and suffering in as an extension of our Sensations in the world right like the fundamental integration function into that system is not an integration function like it has been thus far just over our outputs over our books and our images and our audio right these are all our artifacts yeah but it
(2:13:09) leaves out the entire realm of our embodied Behavior right all of the encodings that we understand to be the sort of qualia space or the subjective experience space of ourselves as an embodied organism um that's absent from the internal representations of these models thus far to the extent that that can't be modeled by our words right like and I'll give you a very concrete example of this like I could have read an infinite number of firsthand accounts of what it's like to hold your child in your arms for the first time to see your
(2:13:47) child for the first first time and it never would have prepared me or given me an inkling of what like I never would have been able to simulate The Experience through the artifacts the only way to experience the experience was to have the experience to be in the experience uh to have all of those behavioral Tendencies align in time and space and in our you know embodied relations such that my actual direct senses and my actual being and the entire evolutionary history that has culminated with me as an entity was manifesting in a way that was
(2:14:27) in direct relation to the continuation of that in a very personal way right and I can still try to talk about this in words but it's not the same thing at all and like you talk about it that way with a child you can do that the same thing applies if people are more into things like let's say psychedelic experiences right it's it's it's equally difficult to come out of an extreme um psychedelic you a psychic experience that one perceives is subjectively Meaningful very intense veilance on that sort of meaning uh Dimension yeah and and
(2:14:57) actually then use words to relate that sense of meaning to another third party especially if that you know the best you can hope for is someone who has had their own version of that and when you point to that significance they can say oh yeah I understand what you're pointing to but I also can't really communicate it to you back in words I can just tell you that I kind of know what you're pointing at right and so the question is like how does that kind of intuitive embodied understanding and comprehension that only manifests
(2:15:26) through being in time how does that work its way into these representations these models of reality because without that they're you know they're not going to they are not going to be of us as whole beings they are going to be of our representations of our experiences and so and I think that's an important distinction that um is also lost on the kind of people who are the most disembodied right um and and who haven't actually tried to bring themselves back out of their models like I love models as much as anyone can love models
(2:16:04) probably but I also understand that there's an extreme danger in that and I need to come back out of that which is why I also move myself into the middle of the woods and make sure that I spend a lot of time in embodied relation ship with natural processes using my body anchoring myself to reality and making sure that my senses are brought back into relation with something Beyond model space um at a Cadence that is actually that had to increase the more that I've gone into pure like purely focusing on this as my my day-to-day the more that I
(2:16:42) Retreat into model space the more I need to be out in the world with embodied cont cont such that I don't lose myself and start drifting um too far out into the abstractions that I have produced so yeah I mean I think that this seems to be essential and I don't think we have a very good way of doing this right now I do think that um looking toward natural intelligence and mechanisms or or or or or processes that are suggested by Explorations in active inference right now um not just active inference but but that ethos and that direction of
(2:17:20) exploring natural intelligence and embodied um emergent intelligence uh that that's That's essential grounding grounding our models you know to the extent that they are powerful they must also be deeply rooted in that uh sense of embodiment not just in the past but also as an ongoing process to which every uh entity human entity hopefully increasing increasingly more life processes um hopefully it samples from larger and larger amounts of of of that life function and therefore in sampling over that life function um becomes an
(2:18:01) extension of that life function as opposed to let's say an extension of like the mechanism function um and those are I think quite distinct so what also bring into that is there's a couple times that you've referred to like sort of the scent neutralization of the generative models as you know either Iris or I mean in some I would say definitely active inference model generative models apply to this as well that you know they're sort of run by one set of people one thing that you know we haven't gotten a talk chance to talk
(2:18:40) about and we'll probably have to talk about more in a future conversation is the notion of how do you decentralize the compression EXs of uh the knowledge that is integrated by those models into you know some sort of distributed data store because I've always viewed it more as that there would be many many different irises people often ask me why there isn't just one and I mean I think you know exactly why there shouldn't be just one and that there would be some energy bound uh distributed data store that is taking
(2:19:20) these compressed tensors or compressed representations of knowledge uh as they are evaluated by or used by many different models and stored in a secured way uh that many future models can build the representations from I I I I view it more like like there is a DNA strand that is the Collective cultural ethos and World observations and that these models are more like the molecules that do the correction uh at when there is the replication of a DNA strand and that ultimately is sort of the model that you know even you and I are have not gotten
(2:20:13) much work into and really needs to develop is that there needs to be sort of Evolution or a merging of these blockchain structures or just distributed data stores and the knowledge in its very dense form um into that Beyond just you know like saving a copy of it you know something more fundamental yeah I mean that like literally so the conversation I mentioned earlier that I had yesterday uh like that exact idea you that was something that I was I was I was speaking with um you uh uh Jordan stuff about when we were discussing you know
(2:20:55) especially the role of something like blockchains uh the role of something like Bitcoin when it comes to and not Bitcoin specifically but proof of work having something that is highly resilient that ends up being a kind of centralized repository for highly compressed encodings uh that can represent as a kind of um DNA over the space of emergent systems that have models right because DNA itself was the way in which like you're saying these molecular mechanisms and all of the emergent structure above them in its
(2:21:30) exploration of function space yeah created a feedback process that compress down into molecular space representations of what works that can then be back unpacked again and experimented with into function space that's this DNA function right but that was all in the in the being a model world but in the having a model world we have to actually because all of this becomes explicit we have to become self sufficiently self-aware that we actually create uh or Steward the creation of a similar kind of um and this is weird
(2:22:06) because there's this Duality here it's a if you did it on a blockchain like like something like a Bitcoin you want it to be capture resistant so it could be highly centralized but because it's capture resistant that centralization actually can become a tool that increases the capacity for decentralized coordination because if every decentralized system can contribute to it and take away from it to some extent then it they could all focus on it their attention on it without having to necessarily be tightly coupled with it
(2:22:36) except when they want to contribute to it or or or you know decode from it right because the decoding can always happen for free the encoding comes with a cost if you want to inscribe yeah but to the extent that anyone can benefit from decoding like think about like what would happen if a a an advanced model were basically leaked and its weights were put onto the blockchain right like now this may or may not be desirable at this point like we might argue that we need a better container for that before it actually makes sense or or could be
(2:23:11) advantageous and that leaking a powerful model and and making it irreversibly accessible on something like a blockchain with respect to its weights or a compressed version of its weights um or a program that could generate those weights if that was a valid compression um you know it's unclear whether that's desirable or not desirable right now but my point is that these kind of mechanisms are almost with 100% certainty going to be the kind of um places where we encode these highly compressed distillations of our
(2:23:44) Collective experimentation over over this space of of of computation Ai and also complex coordination via systems U such as uh the entire other world of like proof of stake and exploration of distributed governance decentralized economics all of that kind of U you know that space where we're seeing a massive amount of experimentation right now um we're seeing a lot of failure we're seeing a lot of parasitism we're seeing a lot of craziness but we're also seeing the seeds of of potentially interesting or useful patterns you know to the extent
(2:24:18) that you know much like uh mutations to the extent that those come into the world and actually provide value um how do you re-encode them into a space where anyone can then replicate those patterns in the world right so if a particular Dow finds the set of configurations and weights over their mechanisms that actually gives rise to really positive capacity for a group to collaborate coordinate and and and be generative as opposed to parasitic or extract um that's a kind of pattern that should be encoded and shared right and it
(2:24:52) should be accessible with very low cost if not free um in something like a blockchain that cannot be easily captured or corrupted uh for for local interests of of any other entity on Earth so yeah I mean I think exactly like the these the the degree to which something like an iris is is centralized or decentralized you know it's an interesting question because to some extent it's a question of you know adoption and evolution and and how all these different threads of that um system um come into usage locally right
(2:25:26) I me obviously you you want to spread it far and wide and have those um sort of seeds cast upon the Winds of potential throughout human uh interest and experimentation such that you know they land and take root and grow in fertile soil um obviously because we're humans people will try to use it for abuse as well and all all these other things that we do but um but yeah me it's again I really do see it as this recapitulation of this natural process at the level of having models as opposed to being models and we are trying to
(2:26:02) figure out how to you know what it looks like to create the kind of social mechanism that is the analog of of DNA right yeah and there I I would add just in summary to try to link it all back together that um there definitely needs to be this could very easily go wrong where it's it's trending towards reducing that uncertainty in our knowledge representations right I I've already seen over like two years with GPT first there was a very wide space where you could explore the longtail you could talk about things that aren't well
(2:26:37) established and more and more it's like there's a regulation into this is the way things are and because they are controlling when that update happens it's harder and harder to do research to that so there whatever compression goes into that distributed Day store it needs to have that preference towards the exploration of the uncertain uncertainty like you were you were speaking of to uh variational free energy versus what was it expected free energy expected free energy like there needs to be uh a tendency not in our compression of
(2:27:11) knowledge to say well this represents truth in it totality and rather this is a representation that is inherently mutating and changing over time um and something that is existing to expand our capacity over time um to exist and Thrive where are neural mechanisms of encoding memory of encoding models um are just a little bit too lossy for long-term yeah and then there's kind of like sedimentary Dynamic there as well where you know to some extent the more the longer that certain aspects of that model have remained stable the more they
(2:28:01) kind of migrate down to a more you know a deeper and more stable structure that doesn't mean that that that layer can't be changed does does get more difficult to change the more energetic constraints on that yeah yeah the more that you have energetic constraints the more that you have dependency the more that you have a history of the world U being congruent with that representation it does get more difficult to change as it migrates down that uh stack but uh but the understanding is that the entire stack all the sedimentary layers even though
(2:28:35) proportional to their level they will be like the top layers will be more volatile proportionally than the the bottom layers but they are all subject to change if you have a uh you know observation or empirical uh experiences of sufficient surprise right and we you know and that reflects what we are like as well right like we have you know we we can be shocked to such an extent that our entire world models it is revealed to us that our entire world models down to their core need to be recalibrated uh if we encounter experiences that are
(2:29:10) sufficiently outside of our model although unfortunately we increasingly are leaning into the tendency to to lean into confirmation bias and to try to say you know you know I'm going to ignore the signals the world is giving to me I'm going to try to force my model on the world again it's like there's always a certain element of interplay between like whether it's beneficial to try to like put your model onto the world or allow the world to transform your model but it always has to be in dialogue and it becomes inherently
(2:29:40) totalitarian when you decide that no matter what I'm not going to change my model and I'm going to push all all of the responsibility for transformation out onto the world as opposed to taking any of that uh in your own model so yeah although so we are we've been on for a while here I do have call coming up um and I want to take a little bit of a break between the two so yeah I just wanted I was G to say you know this feels to me like the the best part of the con conversation so we should have a followup in that vein of like what this
(2:30:12) distributed knowledge representation might look like um is there way you sort of want to tie this all into a bow I mean we've gone for you know two and a half hours now yeah I mean there's there's so much that we' we've covered but I mean I think ultimately again the most the most relevant or the most for me at least the the framework that allows me to place everything within it or the kind of tree that allows me to you know hang the ornaments of knowledge or or perspective upon upon that tree being being seasonal
(2:30:45) here since we're we're going into the holiday season um uh is this question of it goes back to that Z1 question it goes back to that fundamental you know this thing that we were just talking about with respect to acknowledging that fundamentally the process that we are embedded in is more like that of like the basian updating than it is like the frequentist approach of just trying to get as much data as possible that will lead us to a fixed Point uh on the landscape and and we can just put that on the shelf and no longer
(2:31:15) worry about it I think not only that make us uh cognitively lazy but it also brings out the worst aspects of us because it it it you know as soon as you put it on the shelf and and want to move on uh it can be quite frustrating when anyone else comes and picks up that object off the shelf and starts to uh criticize it or say that that might not actually be the way that reality is and you might have to go back to um you might have to especially if if if that has sort of moved down into those deeper sedimentary layers in your model or
(2:31:46) youve built a pawn them that can be quite frustrating and uh and I think that while that frustration will always exist having a perspective and having a worldview and having a cultural uh a culturally holding an understanding that all of that is influx although influx to different degrees I think that allows us to to to get to places that are more desirable like both conversationally it allows to have better conversations because we're not so attached to fixed perspec Ives um we're more interested in in seeing how
(2:32:19) they relate and can inform one another's models and the evolution Improvement of those models it allows us to uh have have better relationships in terms of you know thinking through the implication of economics and our monetary systems and what were their purposes and and how effective are they currently at their purposes and and what might actually allow us to complement or evolve those I mean it just it's a framework in which we can begin to uh I think undergo the Transformations that are necessary um for us to make it
(2:32:49) through the next hundred years uh but I think that also have to be almost you know that have to be mostly voluntary as well right like it's very difficult because because because this has to be voluntary this has to be a process of people coming to see the value in this way of seeing the world um in addition to however they might see the world currently and you know whatever the balance of those over time might be um if you just try to say you need to give up the way you see the world now this is the way it is this is
(2:33:20) what the model says it is and either you agree or we're going to nudge you into agreement U or you know control you beyond your ability to resist uh you know a I don't think that's very adaptive in the long run and B it's certainly not a world that I want to live in so uh yeah it's not not good for human human agency or what you might consider the soul so yeah uh yeah I I think that's kind of the the general framework that I approach all this from and you know I always try to bring things back to that that level because fundamentally
(2:33:54) it has to be good for Humanity it has to be good for you know it has to generally lead to the EMB betterment of human life but also of life in general I want to see you know I want to see us bring about a world in which we can use our knowledge and our models to help to the extent we can uh create more biological complexity more life uh flowing more energy through more systems that are less destructive to one another now obviously you know there's always going to be some amount of there's always going to be some
(2:34:33) amount of conflict and frustration there like I'm not a utopian uh but I do think that there's plenty of room for improvement so yeah wow what a great conversation um I guess I'll say to the audience watching uh because I feel very motivated to have another conversation uh to comment below what particular threads uh you think that we should follow up on I'm always amazed when I hear you speak physically how much in alignment I am with what you say and then I read what you write on Twitter and it's it's almost like there a different version of
(2:35:18) you that you know maybe it's just the translation uh between the textual form and the sort of embodied like uh form of communication where there's there's different signals and feedback between us that can sort of narrow us towards um what's actually being said yeah and part of that's that artifactual issue and part of it you know I some of what I put I put I I write as condensed pointers for myself to come back to um kind of like I've said that it's a shared journal to some extent but this also comes back to the
(2:35:53) fact that you know to be completely honest I would much rather be in relationship with a system trained on my conversational self and like the entire embodied um the entire embodied platform that is me the thinking and being process that is me than than one that is just trained upon the uh kind of disembodied artifacts that I that I put into the world uh and I don't necessarily think that that's a like it's not like I dislike the things I put out into the world I do think that they can be useful I also understand how
(2:36:27) without the context um they can be interpreted in all sorts of ways that aren't necessarily my intention and that can lead to uh conflict or frustration or misom you know miscommunication um but yeah I mean I think that's kind of exactly why it's valuable to figure out how our models of reality can increasingly be informed quite literally informed by that full experience uh that by by by that full set of relationships and um and dynamics that give rise to this kind of an experience as opposed to that which is just mediated by text or
(2:37:03) images or any artifact yeah well I mean in a way this is some artifact too it's just higher resolution maybe we maybe we're moving maybe we're moving towards increasingly high resolution where we end up creating some sort of simulation maybe this is already that maybe there's a higher order reality and we just created this to re process I don't know some some some fraction of us are and there are many incentives that drive people also away from that and there's there's quite the tension right now so yeah this has been great uh
(2:37:45) yeah [Music] [Music]